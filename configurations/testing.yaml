label: [local_search, diffusion_ard] # [local_search, dfs, bfs, random] #[polynomial, polynomial_suminverse, diffusion, diffusion_ard, local_search, random, bfs, dfs]
save_dir: ./logs/useless/
n_exp: 5 # number of experiments with different random seeds
bo_settings:
  batch_size: 1 # batch size
  max_iters: 300 # number of total queries
  max_radius: 10 # the maximum hop distance to the centre node when constructing the local context graph
  n_init: 30 # Initial queried points 
  Q: 1000 # the size of the context ComboSubgraph
  large_Q: False
  exploitation: False
  start_location: random #[random, ei, betweenness, degree] # the initial starting location of search, recommended for large k
  restart_location: queried_best #[same_as_start, queried_best]
  tr_settings:    # settings related to the trust region on the graph search space
    n_nodes_min: 10         # the min number of nodes in the trust region
    trust_region_multiplier: 1.5 
    succ_tol: 10       # success tolerance
    fail_tol: 30      # fail tolerance
problem_name: gnn_attack # [synthetic, epidemic, influence_maximisation, resilience, gnn_attack] the experimental problem type
problem_settings:  
  n: 10000 # number of nodes in the underlying (synthetic) random graphs
  k: 2 # number of combinations
  graph_type: ENZYMES # [ws, ba, grid, contact_network_day1, CS, Facebook, Road, DD, ENZYMES]
  underlying_function: WD # [eigenvector_centrality, ackley, infection_time, independent_cascading, transitivity, JS, WD]
  graph_index: 0 # we choose 2 because its size is relatively suitable for perturbation less than 32
  m: 5
  wsk: 10
  p: 0.1
  noise: 0.5
  infection_percentage_threshold: 0.5
  fraction_infected: 0.1 # Initial fraction infected
  SIR_n_samples: 100
  SIR_n_iterations: 120
  IC_p: 0.05
  IC_n_samples: 1000
